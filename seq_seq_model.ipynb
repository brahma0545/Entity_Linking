{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspiration from NMT\n",
    "# i have used 'vendor name' as start token to the decoder.\n",
    "# as we can see this model is overfitting to the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "lRztipw_LND5",
    "outputId": "27369b95-2caf-4f80-f44f-43b31c89d189"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "yfLhJTQPMDt8",
    "outputId": "70825c3e-8d76-461a-a0e1-eaf926b24f06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_item_nd</th>\n",
       "      <th>canonical_vendor_name</th>\n",
       "      <th>canonical_line_item_name_y</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>management services april #### services</td>\n",
       "      <td>##_minute_ventures</td>\n",
       "      <td>management services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>june web media fee ### ### times ## percent co...</td>\n",
       "      <td>acqcom_digital_marketing</td>\n",
       "      <td>web media fee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business package</td>\n",
       "      <td>adjust</td>\n",
       "      <td>additional attributions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business package</td>\n",
       "      <td>adjust</td>\n",
       "      <td>business package</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seo services</td>\n",
       "      <td>adlift</td>\n",
       "      <td>content marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        line_item_nd  ...  Y\n",
       "0            management services april #### services  ...  1\n",
       "1  june web media fee ### ### times ## percent co...  ...  1\n",
       "2                                   business package  ...  0\n",
       "3                                   business package  ...  1\n",
       "4                                       seo services  ...  0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('deep_learning_features.csv')\n",
    "data['canonical_vendor_name'] =data['canonical_vendor_name'].replace(' ', '_', regex=True)\n",
    "data['line_item_nd']=data['line_item_nd'].str.strip()\n",
    "data['canonical_vendor_name']=data['canonical_vendor_name'].str.strip()\n",
    "data['canonical_line_item_name_y']=data['canonical_line_item_name_y'].str.strip()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8wxkUvU7MTZT"
   },
   "outputs": [],
   "source": [
    "all_strings = []\n",
    "for k in data.columns:\n",
    "    if not k=='Y':\n",
    "        strings=('\\n'.join(data[k])).split('\\n')\n",
    "        all_strings.extend(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5PwYDqHYNOC-"
   },
   "outputs": [],
   "source": [
    "def concat(x):\n",
    "    x,y = x[0],x[1]\n",
    "    return x.strip()+\" \"+y.strip()\n",
    "    \n",
    "data['item_name_x'] = data[['canonical_vendor_name','canonical_line_item_name_y']].apply(lambda x: concat(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6fs6IDiFsMTp"
   },
   "outputs": [],
   "source": [
    "data['item_name_y'] = data['canonical_line_item_name_y'].apply( lambda x: x+\" <END>\")\n",
    "data.drop(['canonical_line_item_name_y','canonical_vendor_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KWv1JTLzM10-",
    "outputId": "36350878-2399-4c13-f07e-aafa0387d6b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, list, 12089, '##_minute_ventures')"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'##_minute_ventures' in all_strings, type(all_strings), all_strings.index('##_minute_ventures'), all_strings[12089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "h3TyIOUvx0Wy"
   },
   "outputs": [],
   "source": [
    "data=data[data['Y']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EN48V7HYnVt6",
    "outputId": "1a270fa0-471b-4cb5-f7c1-3306e07835ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "maklZrL4MK7u"
   },
   "outputs": [],
   "source": [
    "X_train=data.drop(['Y'], axis=1)\n",
    "Y_train=data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ClVVdvw48YP1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oGI-QzXSLa2c"
   },
   "outputs": [],
   "source": [
    "t = Tokenizer(filters='!\"$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "t.fit_on_texts(all_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tv3bzBYDVtp4",
    "outputId": "38ae05bd-2556-41ca-c74b-3423a9a84eed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index['##_minute_ventures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UgbEc6PwM-_O"
   },
   "outputs": [],
   "source": [
    "lengths_x=(X_train['line_item_nd'].str.split().apply(len)).values\n",
    "lengths_y=(X_train['item_name_x'].str.split().apply(len)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "7qmiOalBN7I9",
    "outputId": "86fb8476-f5cf-403d-e890-0df55a68175e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(lengths_x, label=\"input\")\n",
    "sns.kdeplot(lengths_y, label=\"output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "EgTThqH3NhzV",
    "outputId": "81634695-f255-44bd-bc6e-dbdd6410c891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 line_item_nd    lenovo thinkpad x# carbon #th gen ##qd ultrabo...\n",
      "item_name_x     sti_products lenovo thinkpad x# carbon #th gen...\n",
      "item_name_y          lenovo thinkpad x# carbon #th gen ##qd <END>\n",
      "Name: 9934, dtype: object\n",
      "303 line_item_nd    ixcc extra long iphone charger cable ## feet l...\n",
      "item_name_x     amazon_business ixcc extra long iphone charger...\n",
      "item_name_y     ixcc extra long iphone charger cable ## feet l...\n",
      "Name: 4002, dtype: object\n",
      "0 0.0 2.0\n",
      "10 2.0 3.0\n",
      "20 3.0 3.0\n",
      "30 4.0 4.0\n",
      "40 5.0 4.0\n",
      "50 6.0 4.0\n",
      "60 7.0 5.0\n",
      "70 8.0 5.5\n",
      "80 10.0 7.0\n",
      "90 14.5 11.0\n",
      "100 47.0 29.0\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(lengths_x), X_train.iloc[np.argmax(lengths_x)])\n",
    "print(np.argmax(lengths_y), X_train.iloc[np.argmax(lengths_y)])\n",
    "for i in range(0, 101, 10):\n",
    "    print(i, np.percentile(lengths_x, i), np.percentile(lengths_y, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "4X6s82EBOmV_",
    "outputId": "d060cbef-7a1a-405c-ef2f-b1c07c4a9acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 14.5 11.0\n",
      "91 16.350000000000023 11.350000000000023\n",
      "92 17.19999999999999 14.0\n",
      "93 18.0 14.0\n",
      "94 19.0 14.0\n",
      "95 20.0 18.75\n",
      "96 21.0 21.0\n",
      "97 23.0 22.899999999999977\n",
      "98 24.30000000000001 25.0\n",
      "99 26.0 26.0\n",
      "100 47.0 29.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(90, 101, 1):\n",
    "    print(i, np.percentile(lengths_x, i), np.percentile(lengths_y, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "ggpcGv3bOuCZ",
    "outputId": "bb332b91-462e-4de5-9d3f-f54abc4be989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dimes (386, 25)\n",
      "link item (386, 25)\n",
      "link item (386, 25)\n",
      "input dimes (97, 25)\n",
      "link item (97, 25)\n",
      "link item (97, 25)\n"
     ]
    }
   ],
   "source": [
    "input_encoder_train = t.texts_to_sequences(X_train['line_item_nd'])\n",
    "input_encoder_train = pad_sequences(input_encoder_train, maxlen=25,padding='post')\n",
    "print(\"input dimes\",input_encoder_train.shape)\n",
    "\n",
    "input_decoder_train = t.texts_to_sequences(X_train['item_name_x'])\n",
    "input_decoder_train = pad_sequences(input_decoder_train, maxlen=25,padding='post')\n",
    "print(\"link item\",input_decoder_train.shape)\n",
    "\n",
    "output_decoder_train = t.texts_to_sequences(X_train['item_name_y'])\n",
    "output_decoder_train = pad_sequences(output_decoder_train, maxlen=25,padding='post')\n",
    "print(\"link item\",output_decoder_train.shape)\n",
    "\n",
    "#====================\n",
    "input_encoder_eval = t.texts_to_sequences(X_eval['line_item_nd'])\n",
    "input_encoder_eval = pad_sequences(input_encoder_eval, maxlen=25,padding='post')\n",
    "print(\"input dimes\",input_encoder_eval.shape)\n",
    "\n",
    "input_decoder_eval = t.texts_to_sequences(X_eval['item_name_x'])\n",
    "input_decoder_eval = pad_sequences(input_decoder_eval, maxlen=25,padding='post')\n",
    "print(\"link item\",input_decoder_eval.shape)\n",
    "\n",
    "output_decoder_eval = t.texts_to_sequences(X_eval['item_name_y'])\n",
    "output_decoder_eval = pad_sequences(output_decoder_eval, maxlen=25,padding='post')\n",
    "print(\"link item\",output_decoder_eval.shape)\n",
    "#====================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bEljUylJQYje"
   },
   "outputs": [],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
    "# !unzip glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jGEQSW_z_EZK"
   },
   "outputs": [],
   "source": [
    "vocab = set(dict(t.word_index.items()).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KoC6iOXlBClU"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RBQfT6bx-lej",
    "outputId": "ab6b5055-e149-4dd4-b9ae-38141782bd32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found word vectors  1657 out of 1822\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.42B.300d.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word  = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        if word in vocab:\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "print('Found word vectors ', len(embeddings_index), \"out of\", vocab_size)\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Uh9iOMGIQ8Vr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dot, Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "acFAsKukf_vb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def auroc(y_true, y_pred):\n",
    "    y_true= tf.reshape(y_true, shape=(-1,))\n",
    "    if tf.unique(y_true)[0].shape[0]==1:\n",
    "        print(tf.unique(y_true)[0].shape, \"hello\")\n",
    "        return 0.5\n",
    "    else:\n",
    "        return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PQfAKHFURPpn"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, input_length, enc_units):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.enc_units= enc_units\n",
    "        self.lstm_output = 0\n",
    "        self.state_h=0\n",
    "        self.state_c=0\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
    "                           mask_zero=True, name=\"embedding_layer_encoder\", weights=[embedding_matrix], trainable=False)\n",
    "        self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "    def call(self, input_sentances, training=True):\n",
    "        # print(\"ENCODER ==> INPUT SQUENCES SHAPE :\",input_sentances.shape)\n",
    "        input_embedd                           = self.embedding(input_sentances)\n",
    "        # print(\"ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE :\",input_embedd.shape)\n",
    "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
    "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "    def get_states(self):\n",
    "        return self.state_h,self.state_c\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, input_length, dec_units):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim= self.vocab_size, output_dim=self.embedding_dim, input_length=input_shape,\n",
    "                           mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix], trainable=False)\n",
    "        self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True, name=\"Encoder_LSTM\")\n",
    "        \n",
    "    def call(self, target_sentances, state_h, state_c):\n",
    "        # print(\"DECODER ==> INPUT SQUENCES SHAPE :\",target_sentances.shape)\n",
    "        target_embedd           = self.embedding(target_sentances)\n",
    "        # print(\"WE ARE INITIALIZING DECODER WITH ENCODER STATES :\",state_h.shape, state_c.shape)\n",
    "        lstm_output, _,_        = self.lstm(target_embedd, initial_state=[state_h, state_c])\n",
    "        return lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Jsg7uvRw3Kix"
   },
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size):\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.encoder = Encoder(vocab_size=vocab_size, embedding_dim=300, input_length=encoder_inputs_length, enc_units=100)\n",
    "        self.decoder = Decoder(vocab_size=vocab_size, embedding_dim=300, input_length=decoder_inputs_length, dec_units=100)\n",
    "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
    "        self.drop  = Dropout(rate=0.4)\n",
    "        \n",
    "    def call(self, data):\n",
    "        input,output = data[0], data[1]\n",
    "        # print(\"=\"*20, \"ENCODER\", \"=\"*20)\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
    "        # print(\"-\"*27)\n",
    "        # print(\"ENCODER ==> OUTPUT SHAPE\",encoder_output.shape)\n",
    "        # print(\"ENCODER ==> HIDDEN STATE SHAPE\",encoder_h.shape)\n",
    "        # print(\"ENCODER ==> CELL STATE SHAPE\", encoder_c.shape)\n",
    "        # print(\"=\"*20, \"DECODER\", \"=\"*20)\n",
    "        decoder_output                       = self.decoder(output, encoder_h, encoder_c)\n",
    "        dropout                              = self.drop(decoder_output)\n",
    "        output                               = self.dense(dropout)\n",
    "        # print(\"-\"*27)\n",
    "        # print(\"FINAL OUTPUT SHAPE\",output.shape)\n",
    "        # print(\"=\"*50)\n",
    "        return output\n",
    "without_vendor  = MyModel(encoder_inputs_length=25,decoder_inputs_length=25,output_vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PaO68nO6xYE6",
    "outputId": "16099a7f-94d0-4220-db53-3d39c18877ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 4s 293ms/step - loss: 1.7433 - val_loss: 1.6893\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 1.5735 - val_loss: 1.4800\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 1.3324 - val_loss: 1.4007\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 2s 130ms/step - loss: 1.2553 - val_loss: 1.4157\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 1.2273 - val_loss: 1.4085\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 1.2044 - val_loss: 1.3926\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 1.1811 - val_loss: 1.3761\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 1.1549 - val_loss: 1.3572\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 1.1382 - val_loss: 1.3470\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 1.1149 - val_loss: 1.3376\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 1.0931 - val_loss: 1.3306\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 1.0747 - val_loss: 1.3153\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 1.0587 - val_loss: 1.3081\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 2s 136ms/step - loss: 1.0401 - val_loss: 1.3094\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 1.0227 - val_loss: 1.2911\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 1.0048 - val_loss: 1.2889\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.9872 - val_loss: 1.2814\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.9688 - val_loss: 1.2770\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.9564 - val_loss: 1.2681\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.9381 - val_loss: 1.2592\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.9197 - val_loss: 1.2526\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 2s 140ms/step - loss: 0.9066 - val_loss: 1.2506\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.8903 - val_loss: 1.2457\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.8751 - val_loss: 1.2442\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.8560 - val_loss: 1.2401\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.8439 - val_loss: 1.2277\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.8304 - val_loss: 1.2323\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.8172 - val_loss: 1.2228\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.8017 - val_loss: 1.2194\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.7894 - val_loss: 1.2180\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.7725 - val_loss: 1.2250\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.7596 - val_loss: 1.2326\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.7434 - val_loss: 1.2191\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.7311 - val_loss: 1.2219\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.7211 - val_loss: 1.2228\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.7079 - val_loss: 1.2094\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.6962 - val_loss: 1.2049\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.6846 - val_loss: 1.2119\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.6664 - val_loss: 1.1813\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.6613 - val_loss: 1.1928\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.6452 - val_loss: 1.1994\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 2s 130ms/step - loss: 0.6296 - val_loss: 1.2012\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.6196 - val_loss: 1.2015\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.6093 - val_loss: 1.2030\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.5991 - val_loss: 1.1941\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.5824 - val_loss: 1.2068\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.5767 - val_loss: 1.1855\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.5690 - val_loss: 1.2102\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.5545 - val_loss: 1.2083\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.5443 - val_loss: 1.2092\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.5290 - val_loss: 1.1999\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.5235 - val_loss: 1.1949\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 2s 130ms/step - loss: 0.5102 - val_loss: 1.1977\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.5011 - val_loss: 1.1875\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.4878 - val_loss: 1.1894\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 2s 137ms/step - loss: 0.4810 - val_loss: 1.1947\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 2s 141ms/step - loss: 0.4674 - val_loss: 1.1943\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.4583 - val_loss: 1.2021\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.4510 - val_loss: 1.1929\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 2s 150ms/step - loss: 0.4468 - val_loss: 1.1892\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.4435 - val_loss: 1.2082\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.4297 - val_loss: 1.1981\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.4171 - val_loss: 1.1813\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.4130 - val_loss: 1.2020\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.3965 - val_loss: 1.2157\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.3888 - val_loss: 1.2026\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.3823 - val_loss: 1.1931\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.3734 - val_loss: 1.2002\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.3696 - val_loss: 1.2102\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.3569 - val_loss: 1.1921\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.3468 - val_loss: 1.2027\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.3425 - val_loss: 1.1910\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.3362 - val_loss: 1.1965\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.3310 - val_loss: 1.2033\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.3201 - val_loss: 1.1790\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.3142 - val_loss: 1.1893\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.3129 - val_loss: 1.1954\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.3065 - val_loss: 1.1971\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.2988 - val_loss: 1.1793\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.2910 - val_loss: 1.1831\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.2872 - val_loss: 1.1766\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 2s 136ms/step - loss: 0.2761 - val_loss: 1.1960\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.2677 - val_loss: 1.1872\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.2677 - val_loss: 1.1860\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.2599 - val_loss: 1.1988\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.2555 - val_loss: 1.1979\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.2515 - val_loss: 1.1861\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 2s 135ms/step - loss: 0.2454 - val_loss: 1.1884\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.2426 - val_loss: 1.1875\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.2349 - val_loss: 1.1946\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.2329 - val_loss: 1.2003\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.2271 - val_loss: 1.1698\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 2s 129ms/step - loss: 0.2232 - val_loss: 1.1973\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.2153 - val_loss: 1.1855\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.2146 - val_loss: 1.1861\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 2s 132ms/step - loss: 0.2101 - val_loss: 1.1887\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.2061 - val_loss: 1.1748\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 2s 130ms/step - loss: 0.2024 - val_loss: 1.1743\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 2s 131ms/step - loss: 0.1981 - val_loss: 1.1907\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 2s 137ms/step - loss: 0.1931 - val_loss: 1.1798\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  707000    \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  707000    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  184022    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,598,022\n",
      "Trainable params: 504,822\n",
      "Non-trainable params: 1,093,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loss_object = loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "without_vendor.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n",
    "\n",
    "without_vendor.fit([input_encoder_train, input_decoder_train], output_decoder_train, epochs=100, \\\n",
    "          validation_data=([input_encoder_eval, input_decoder_eval], output_decoder_eval),\\\n",
    "          )\n",
    "without_vendor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "id": "PAPyu_RM_hoN",
    "outputId": "99211d77-1989-4ea4-fb18-e998077fd64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Inference ==============================\n",
      "[1498 1499    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "1776\n",
      "-------------------- started predition --------------------\n",
      "at time step 0 the word is  ##_minute_ventures\n",
      "at time step 0 the word is  [[42]] disposable\n",
      "at time step 0 the word is  [[78]] charge\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[93]] camera\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[25]] macbook\n",
      "at time step 0 the word is  [[79]] annual\n",
      "at time step 0 the word is  [[62]] data\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[70]] disks\n",
      "at time step 0 the word is  [[23]] inch\n",
      "at time step 0 the word is  [[23]] inch\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 30, \"Inference\", \"=\" * 30)\n",
    "print(input_encoder_train[0])\n",
    "print(t.word_index['##_minute_ventures'])\n",
    "enc_output, enc_state_h, enc_state_c = without_vendor.layers[0](np.expand_dims(input_encoder_train[0], 0))\n",
    "states_values = [enc_state_h, enc_state_c]\n",
    "pred = []\n",
    "cur_vec = np.array([[1776]])\n",
    "print('-'*20,\"started predition\",\"-\"*20)\n",
    "print(\"at time step 0 the word is \", t.index_word[1776])\n",
    "for i in range(25):\n",
    "    cur_emb = without_vendor.layers[1].embedding(cur_vec)\n",
    "    [infe_output, state_h, state_c] = without_vendor.layers[1].lstm(cur_emb, initial_state=states_values)\n",
    "    states_values = [state_h, state_c]\n",
    "    # np.argmax(infe_output) will be a single value, which represents the the index of predicted word\n",
    "    # but to pass this data into next time step embedding layer, we are reshaping it into (1,1) shape\n",
    "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "    print(\"at time step 0 the word is \", cur_vec, t.index_word[cur_vec[0][0]])\n",
    "    pred.append(cur_vec)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "seq-seq_model",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
